# -*- coding: utf-8 -*-
"""Credit Card Fraud Detection Model

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/scratchpad/credit-card-fraud-detection-model.0ce0f023-d426-4532-ab4e-385340208a4e.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20250506/auto/storage/goog4_request%26X-Goog-Date%3D20250506T043631Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D1d8dfdcee16262e963a40d52720cc7057afb8974278f2ac5369aebcc8e72e3039ca9bc6d2dd33441c2b3068e3efde05598f89a6d7be0e4ae035a9e8c914cf6b9e480a1a1fc25ae58883af341bc4fa243849ce43c44e05533c088847999df10e802c4f1e104a9a45126fe218c351e79c81bfd5c2e9cbc3c582448b97d52590393a8949767a9240d06f9fcc38acff72193a65bda7f52d5cc33545a1d03e6b81a0299af3e6ad6aac243eb2341cc610b81dbb6b39ecf132e2621c5e70a98327f3f2a38d7d163e8012108dd57ca8f2eaf1f9cce4a46d495b548e210c97a9349505f85fc79e6c6fee232da7346d4ce3e1a70ff0d9db97ed069f427b0a9c17445a0a36d
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.
import kagglehub
kartik2112_fraud_detection_path = kagglehub.dataset_download('kartik2112/fraud-detection')

print('Data source import complete.')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder, StandardScaler, PowerTransformer
from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix
from sklearn.model_selection import GridSearchCV, StratifiedKFold
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from imblearn.over_sampling import ADASYN
from imblearn.under_sampling import TomekLinks

# Load Data
train_df = pd.read_csv("/kaggle/input/fraud-detection/fraudTrain.csv")
test_df = pd.read_csv("/kaggle/input/fraud-detection/fraudTest.csv")

train_df.head()

test_df.head()

# Display basic info
print("Train Data Info:")
train_df.info()

print("\nTest Data Info:")
test_df.info()

# Check for missing values
print("\nMissing Values in Train Data:")
print(train_df.isnull().sum())
print("\nMissing Values in Test Data:")
print(test_df.isnull().sum())

# Data Distribution
train_df.describe()

# Encoding categorical variables
categorical_columns = ['category', 'gender', 'state', 'job']
encoders = {}

for col in categorical_columns:
    encoder = LabelEncoder()
    train_df[col] = encoder.fit_transform(train_df[col])

    # Save encoder for later use
    encoders[col] = encoder

    # Handle unseen categories in test set
    test_df[col] = test_df[col].apply(lambda x: encoder.transform([x])[0] if x in encoder.classes_ else -1)

# Standardization
scaler = StandardScaler()
numeric_columns = ['amt', 'lat', 'long']
train_df[numeric_columns] = scaler.fit_transform(train_df[numeric_columns])
test_df[numeric_columns] = scaler.transform(test_df[numeric_columns])

# Feature Selection
X = train_df.drop(columns=['is_fraud'])
y = train_df['is_fraud']

# Mutual Information
mi_scores = mutual_info_classif(X, y, random_state=42)
mi_scores = pd.Series(mi_scores, index=X.columns).sort_values(ascending=False)

# Chi-Square Test
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)
chi_scores, _ = chi2(X_scaled, y)
chi_scores = pd.Series(chi_scores, index=X.columns).sort_values(ascending=False)

# Convert transaction date to datetime
train_df["trans_date_trans_time"] = pd.to_datetime(train_df["trans_date_trans_time"])
test_df["trans_date_trans_time"] = pd.to_datetime(test_df["trans_date_trans_time"])

# Feature Engineering
for df in [train_df, test_df]:
    df["hour"] = df["trans_date_trans_time"].dt.hour
    df["day_of_week"] = df["trans_date_trans_time"].dt.dayofweek
    df.drop(columns=["trans_date_trans_time", "first", "last", "street", "dob", "trans_num", "cc_num"], inplace=True)

# Encode categorical variables
label_cols = ["merchant", "category", "state", "city", "job", "gender"]
label_encoders = {col: LabelEncoder() for col in label_cols}

for col in label_cols:
    for df in [train_df, test_df]:
        df[col] = label_encoders[col].fit_transform(df[col])

# Define features and target
X_train, y_train = train_df.drop(columns=["is_fraud"]), train_df["is_fraud"]
X_test, y_test = test_df.drop(columns=["is_fraud"]), test_df["is_fraud"]

# Feature Transformation
scaler = StandardScaler()
power_transformer = PowerTransformer()
X_train = power_transformer.fit_transform(scaler.fit_transform(X_train))
X_test = power_transformer.transform(scaler.transform(X_test))